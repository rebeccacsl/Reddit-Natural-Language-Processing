{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0739c2a",
   "metadata": {},
   "source": [
    "# Project 3: Modelling of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ca274",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b7321",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9a1e6cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import libraries for data analysis'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cea2770",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a2c072aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load processed statistics and machine learning dataset'''\n",
    "stats_ml_df = pd.read_csv('../datasets/stats_ml_processed_df.csv',index_col=False)\n",
    "\n",
    "'''convert datetime from string type to datetime'''\n",
    "stats_ml_df['datetime'] =  pd.to_datetime(stats_ml_df['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "de73d781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1977 entries, 0 to 1976\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   title                   1977 non-null   object             \n",
      " 1   sub_text                1822 non-null   object             \n",
      " 2   id                      1977 non-null   object             \n",
      " 3   author                  1973 non-null   object             \n",
      " 4   score                   1977 non-null   int64              \n",
      " 5   upvote_ratio            1977 non-null   float64            \n",
      " 6   comments_list           1977 non-null   object             \n",
      " 7   datetime                1977 non-null   datetime64[ns, UTC]\n",
      " 8   year                    1977 non-null   int64              \n",
      " 9   month                   1977 non-null   int64              \n",
      " 10  joined_data             1977 non-null   object             \n",
      " 11  tokenize_join_comments  1977 non-null   object             \n",
      " 12  is_ml                   1977 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(4), object(7)\n",
      "memory usage: 200.9+ KB\n"
     ]
    }
   ],
   "source": [
    "'''view loaded dataframe'''\n",
    "stats_ml_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5054adc",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb867455",
   "metadata": {},
   "source": [
    "|Feature |Type| Decription|\n",
    "|---|---|---|\n",
    "|title|string object|Title of Subreddit Posts|\n",
    "|sub_text|string object|Additional description followed by Title. This field may be empty|\n",
    "|id|string object|Unique subreddit id of each post|\n",
    "|author|string object|author of posts|\n",
    "|score|int|The number of upvotes for the submission|\n",
    "|upvote_ratio|float|The percentage of upvotes from all votes on the submission|\n",
    "|comments_list|string object|Extracted comments including the replies|\n",
    "|datetime|datetime|datetime on when the post was posted.|\n",
    "|year|int|year information extracted from datetime.|\n",
    "|month|int|month information extracted from datetime.|\n",
    "|joined_data|string object|joined_data containing information from title, sub_text and comments|\n",
    "|tokenize_join_comments|string object|tokenised with stopped wordsremoved from joined_data column|\n",
    "|is_ml|int|1 indicates that the content came from machine learning subreddit. 0 indicates that the content came from statistics subreddit.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5f77d",
   "metadata": {},
   "source": [
    "# (M1) Modelling (Baseline Model) | Using tokenize_join_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e23947",
   "metadata": {},
   "source": [
    "Modelling will be done on tokenize_join_comments for this prediction as the focus will be on how effective is the joined information of title, subtext and comments for the prediction on whether it is a Machine Learning or Statistics thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "322f02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Instantiate X and y for prediction'''\n",
    "X_extracted = stats_ml_df['tokenize_join_comments']\n",
    "y_extracted = stats_ml_df['is_ml']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c0e399",
   "metadata": {},
   "source": [
    "## Count Vectoriser Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "756068ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a CountVectorizer'''\n",
    "vectorizer_cv = CountVectorizer()\n",
    "\n",
    "'''Convert text into numerical features'''\n",
    "X = vectorizer_cv.fit_transform(X_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34451ac9",
   "metadata": {},
   "source": [
    "### Logistic Regression - Count Vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f08be506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Logistic Regression Count Vectoriser:\n",
      "accuracy:  0.972\n",
      "Coefficient Mean:  0.00021273513982014475\n"
     ]
    }
   ],
   "source": [
    "'''Train Test Split data for modelling'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_extracted, test_size=0.2, random_state=42)\n",
    "\n",
    "'''Instantiate Logistic Regression Model'''\n",
    "log_reg_model_cv = LogisticRegression()\n",
    "\n",
    "'''Train and Fit model'''\n",
    "log_reg_model_cv.fit(X_train, y_train)\n",
    "\n",
    "'''Get predictions on test set'''\n",
    "predictions = log_reg_model_cv.predict(X_test)\n",
    "\n",
    "'''Calculate accuracy score'''\n",
    "log_accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "'''Calculate mean coefficient'''\n",
    "coefficients_mean = log_reg_model_cv.coef_.mean()\n",
    "\n",
    "print('Model Performance for Logistic Regression Count Vectoriser:')\n",
    "print('accuracy: ', round(log_accuracy,3))\n",
    "print('Coefficient Mean: ', coefficients_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c4385",
   "metadata": {},
   "source": [
    "### Random Forest- Count Vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b227d242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Random Forest  Count Vectoriser:\n",
      "accuracy:  0.9722222222222222\n",
      "importance 2.571619606027877e-05\n"
     ]
    }
   ],
   "source": [
    "'''Train Test Split data for modelling'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_extracted, test_size=0.2, random_state=42)\n",
    "\n",
    "'''Instantiate Decision Tree Model'''\n",
    "rf_model_cv = RandomForestClassifier()\n",
    "\n",
    "'''Train and Fit model'''\n",
    "rf_model_cv.fit(X_train, y_train)\n",
    "\n",
    "'''Get predictions on test set'''\n",
    "predictions = rf_model_cv.predict(X_test)\n",
    "\n",
    "'''Get feature importance'''\n",
    "importances_mean = rf_model_cv.feature_importances_.mean()\n",
    "\n",
    "'''Calculate accuracy score'''\n",
    "rf_accuracy = accuracy_score(y_test, predictions)\n",
    "print('Model Performance for Random Forest  Count Vectoriser:')\n",
    "print('accuracy: ', rf_accuracy)\n",
    "print('importance', importances_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3efa3f",
   "metadata": {},
   "source": [
    "## TFIDVectoriser Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "174593f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a CountVectorizer'''\n",
    "vectorizer_tv = TfidfVectorizer()\n",
    "\n",
    "'''Convert text into numerical features'''\n",
    "X = vectorizer_tv.fit_transform(X_extracted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4ab7cc",
   "metadata": {},
   "source": [
    "### Logistic Regression - TFIDVectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e35cffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Logistic Regression Count Vectoriser:\n",
      "accuracy:  0.9823232323232324\n",
      "Coefficient Mean:  0.0021066192306905306\n"
     ]
    }
   ],
   "source": [
    "'''Train Test Split data for modelling'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_extracted, test_size=0.2, random_state=42)\n",
    "\n",
    "'''Instantiate Logistic Regression Model'''\n",
    "log_reg_model_tv = LogisticRegression()\n",
    "\n",
    "'''Train and Fit model'''\n",
    "log_reg_model_tv.fit(X_train, y_train)\n",
    "\n",
    "'''Get predictions on test set'''\n",
    "predictions = log_reg_model_tv.predict(X_test)\n",
    "\n",
    "'''Calculate accuracy score'''\n",
    "log_accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "'''Calculate mean coefficient'''\n",
    "coefficients_mean = log_reg_model_tv.coef_.mean()\n",
    "\n",
    "print('Model Performance for Logistic Regression Count Vectoriser:')\n",
    "print('accuracy: ', log_accuracy)\n",
    "print('Coefficient Mean: ', coefficients_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3790b47",
   "metadata": {},
   "source": [
    "### Random Forest - TFIDVectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "61b30b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Random Forest  Count Vectoriser:\n",
      "accuracy:  0.9722222222222222\n",
      "importance 2.5716196060278763e-05\n"
     ]
    }
   ],
   "source": [
    "'''Train Test Split data for modelling'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_extracted, test_size=0.2, random_state=42)\n",
    "\n",
    "'''Instantiate Decision Tree Model'''\n",
    "rf_model_tv = RandomForestClassifier()\n",
    "\n",
    "'''Train and Fit model'''\n",
    "rf_model_tv.fit(X_train, y_train)\n",
    "\n",
    "'''Get predictions on test set'''\n",
    "predictions = rf_model_tv.predict(X_test)\n",
    "\n",
    "'''Get feature importance'''\n",
    "importances_mean = rf_model_tv.feature_importances_.mean()\n",
    "\n",
    "'''Calculate accuracy score'''\n",
    "rf_accuracy = accuracy_score(y_test, predictions)\n",
    "print('Model Performance for Random Forest  Count Vectoriser:')\n",
    "print('accuracy: ', rf_accuracy)\n",
    "print('importance', importances_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f75dc9",
   "metadata": {},
   "source": [
    "\n",
    "|               | Log Regression(CV)| Log Regression(TV)|Random Forest(CV) |Random Forest(TV)|\n",
    "|---------------|-------------------|-------------------|------------------|-----------------|\n",
    "|**accuracy**   | 0.972             | 0.982             | 0.967            |0.972            |\n",
    "|**coef**       |0.0002127          | 0.002106          | -                |-                |\n",
    "|**importance** |-                  | -                 |2.5716196e-05     |2.57161e-05      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542a784",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae12a22",
   "metadata": {},
   "source": [
    "- The analysis is done between CountVectorizer and TfidVectoriser to understand how it can impact the accuracy level. CountVectorizer is a technique that converts text document into a matrix of token count. TfidVectoriser similarly converts text document into a matrix representation of token and also consider the relative importance of the word in the entire corpus.\n",
    "- Logistic Regression using TfidVectoriser is the best performing baseline model with an accuracy of 0.982. The coefficient oof 0.002106 is around 10 times larger than the coefficient of 0.0002127 for Logistic Regression CountVectoriser. A larger positive coefficient represents a stronger influence in prediction with a positive association between feature and the positive label.\n",
    "- It is observed that Random Forest TfidVectoriser model performs better than RandomForest CountVectoriser.\n",
    "- For the current dataset, TfidVectoriser results in a higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2bdbb",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1b0fdd",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Logistic Regression TfidVectorisor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ec8f91",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning will be done using GridSearch CV to identify the best parameters to be used for the Logistic Regression Model with TfidVectorisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a869546f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv: 2\n",
      "Best Parameters: {'C': 10.0, 'penalty': 'l2'}\n",
      "Best Score: 0.9512946278545024\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv: 3\n",
      "Best Parameters: {'C': 10.0, 'penalty': 'l2'}\n",
      "Best Score: 0.9538266919671093\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv: 4\n",
      "Best Parameters: {'C': 10.0, 'penalty': 'l2'}\n",
      "Best Score: 0.9531997187060478\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\R\\Installer\\20221005_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv: 5\n",
      "Best Parameters: {'C': 10.0, 'penalty': 'l2'}\n",
      "Best Score: 0.9557281475861519\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "'''Define hyperparameter grid'''\n",
    "param_grid_log_tv = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'penalty': [  'none', 'l2'] # only include l2 and none for penalty due to error message\n",
    "}\n",
    "\n",
    "'''loop through cv from 0 to 5 to find the parameters with the best score'''\n",
    "for num in range(2,6):\n",
    "    '''Instantiate logistic regression model and GridSearchCv'''\n",
    "    model = LogisticRegression()\n",
    "    grid_search = GridSearchCV(estimator=log_reg_model_tv, param_grid=param_grid_log_tv, cv=num)\n",
    "\n",
    "    '''fit GridSearchCv to the model'''\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    '''print best parameters and best score'''\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    print('cv:',num)\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Score:\", best_score)\n",
    "    print('-'*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2d9c8",
   "metadata": {},
   "source": [
    "\n",
    "| CV            |Best Score for Logistic Regression TfidVectoriser|  \n",
    "|---------------|-------------------------------------------------|\n",
    "|**2**          |0.951                                            | \n",
    "|**3**          |0.954                                            | \n",
    "|**4**          |0.953                                            | \n",
    "|**5**          |0.956                                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a88234",
   "metadata": {},
   "source": [
    "Observed that the best score of 0.956 is lower than the highest accuracy of 0.982 for TfidVectoriser in the baseline logistic regression model. Hence the following parameters will not be used for the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6296bb6",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Random Forest TfidVectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "28d6fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv: 2\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best Score: 0.9462353374193858\n",
      "-----\n",
      "cv: 3\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Best Score: 0.9487666034155599\n",
      "-----\n",
      "cv: 4\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Score: 0.9500319652218387\n",
      "-----\n",
      "cv: 5\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Score: 0.9512957712734098\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "'''Train Test Split data for modelling'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_extracted, test_size=0.2, random_state=42)\n",
    "\n",
    "'''Define hyperparameter grid'''\n",
    "param_grid_rf_tv = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 5, 10],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "'''loop through cv from 0 to 5 to find the parameters with the best score'''\n",
    "for num in range(2,6):\n",
    "    '''Instantiate logistic regression model and GridSearchCv'''\n",
    "    model = LogisticRegression()\n",
    "    grid_search = GridSearchCV(estimator=rf_model_tv, param_grid=param_grid_rf_tv, cv=num)\n",
    "\n",
    "    '''fit GridSearchCv to the model'''\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    '''print best parameters and best score'''\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    print('cv:',num)\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Score:\", best_score)\n",
    "    print('-'*5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca074f7",
   "metadata": {},
   "source": [
    "| CV            |Best Score for Logistic Regression TfidVectoriser|  \n",
    "|---------------|-------------------------------------------------|\n",
    "|**2**          |0.946                                            | \n",
    "|**3**          |0.949                                            | \n",
    "|**4**          |0.950                                            | \n",
    "|**5**          |0.951                                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef077728",
   "metadata": {},
   "source": [
    "Observed that the best score of 0.951 is lower than the highest accuracy of 0.972 for TfidVectoriser in the baseline random forest model. Hence the following parameters will not be used for the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20934831",
   "metadata": {},
   "source": [
    "# (M2) Modelling | Using tokenize_join_comments and author"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db880a73",
   "metadata": {},
   "source": [
    "Modellling will be done using tokenized_join_comments and author to understand if author has an impact on the prediction result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a3641",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef32944",
   "metadata": {},
   "source": [
    "Earlier in the EDA process it was observed the author has missing a small amount of rows missing. As the objective of the analysis was on the joined comments it was previously not removed. For the purpose of this analysis, rows from author will be removed. The impact is deemed to be negligible as only 4 rows will be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bbca16fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''creates a copy of the dataframes before preprocessing'''\n",
    "stats_ml_df_auth_del = stats_ml_df.copy()\n",
    "\n",
    "'''remove rows from where column 'author' is null '''\n",
    "stats_ml_df_auth_del = stats_ml_df_auth_del.dropna(subset=['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dd2153e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1973 entries, 0 to 1976\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   title                   1973 non-null   object             \n",
      " 1   sub_text                1818 non-null   object             \n",
      " 2   id                      1973 non-null   object             \n",
      " 3   author                  1973 non-null   object             \n",
      " 4   score                   1973 non-null   int64              \n",
      " 5   upvote_ratio            1973 non-null   float64            \n",
      " 6   comments_list           1973 non-null   object             \n",
      " 7   datetime                1973 non-null   datetime64[ns, UTC]\n",
      " 8   year                    1973 non-null   int64              \n",
      " 9   month                   1973 non-null   int64              \n",
      " 10  joined_data             1973 non-null   object             \n",
      " 11  tokenize_join_comments  1973 non-null   object             \n",
      " 12  is_ml                   1973 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(4), object(7)\n",
      "memory usage: 215.8+ KB\n"
     ]
    }
   ],
   "source": [
    "'''check dataframe that rows where author is null is removed'''\n",
    "stats_ml_df_auth_del.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fffedf",
   "metadata": {},
   "source": [
    "- Validated that the rows where author is null is removed. \n",
    "- Observed that the the rows which removed includes sub_text rows which are null.\n",
    "- For the purpose of this analysis, the decision is made not te to remove the rows with missing value for 'sub_text'as the number of rows to be removed will be significant. The columns of focused would also be tokenize_join_comments hence its deemed to be acceptable to retained the rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4c98bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Instantiate X and y for prediction'''\n",
    "X_extracted2 = stats_ml_df_auth_del['tokenize_join_comments']\n",
    "y_extracted2 = stats_ml_df_auth_del['is_ml']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f64ddf3",
   "metadata": {},
   "source": [
    "## Count Vectoriser Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3f376ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a CountVectorizer'''\n",
    "vectorizer_cv2 = CountVectorizer()\n",
    "\n",
    "'''Convert text into numerical features'''\n",
    "X2 = vectorizer_cv2.fit_transform(X_extracted2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55bad93",
   "metadata": {},
   "source": [
    "### Logistic Regression - Count Vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "72c048dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Logistic Regression Count Vectoriser:\n",
      "accuracy:  0.954\n",
      "Coefficient Mean:  0.002219625576809319\n"
     ]
    }
   ],
   "source": [
    "'''Train Test Split data for modelling'''\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y_extracted2, test_size=0.2, random_state=42)\n",
    "\n",
    "'''Instantiate Logistic Regression Model'''\n",
    "log_reg_model_cv2 = LogisticRegression()\n",
    "\n",
    "'''Train and Fit model'''\n",
    "log_reg_model_cv2.fit(X_train2, y_train2)\n",
    "\n",
    "'''Get predictions on test set'''\n",
    "predictions2 = log_reg_model_cv2.predict(X_test2)\n",
    "\n",
    "'''Calculate accuracy score'''\n",
    "log_accuracy2 = accuracy_score(y_test2, predictions2)\n",
    "\n",
    "'''Calculate mean coefficient'''\n",
    "coefficients_mean2 = log_reg_model_cv2.coef_.mean()\n",
    "\n",
    "print('Model Performance for Logistic Regression Count Vectoriser:')\n",
    "print('accuracy: ', round(log_accuracy2,3))\n",
    "print('Coefficient Mean: ', coefficients_mean2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd949310",
   "metadata": {},
   "source": [
    "### Random Forest- Count Vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "82f939bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Random Forest  Count Vectoriser:\n",
      "accuracy:  0.9417721518987342\n",
      "importance 2.5730091341824264e-05\n"
     ]
    }
   ],
   "source": [
    "'''Train Test Split data for modelling'''\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y_extracted2, test_size=0.2, random_state=42)\n",
    "\n",
    "'''Instantiate Random Forest Model'''\n",
    "rf_model_cv2 = RandomForestClassifier()\n",
    "\n",
    "'''Train and Fit model'''\n",
    "rf_model_cv2.fit(X_train2, y_train2)\n",
    "\n",
    "'''Get predictions on test set'''\n",
    "predictions2 = rf_model_cv2.predict(X_test2)\n",
    "\n",
    "'''Get feature importance'''\n",
    "importances_mean2 = rf_model_cv2.feature_importances_.mean()\n",
    "\n",
    "'''Calculate accuracy score'''\n",
    "rf_accuracy2 = accuracy_score(y_test2, predictions2)\n",
    "print('Model Performance for Random Forest  Count Vectoriser:')\n",
    "print('accuracy: ', rf_accuracy2)\n",
    "print('importance', importances_mean2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22561e0",
   "metadata": {},
   "source": [
    "## TFIDVectoriser Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b10d9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a CountVectorizer'''\n",
    "vectorizer_tv2 = TfidfVectorizer()\n",
    "\n",
    "'''Convert text into numerical features'''\n",
    "X2 = vectorizer_tv2.fit_transform(X_extracted2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17673b",
   "metadata": {},
   "source": [
    "### Logistic Regression - TFIDVectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8a933826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Logistic Regression Count Vectoriser:\n",
      "accuracy:  0.9544303797468354\n",
      "Coefficient Mean:  0.002219625576809319\n"
     ]
    }
   ],
   "source": [
    "'''Train Test Split data for modelling'''\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y_extracted2, test_size=0.2, random_state=42)\n",
    "\n",
    "'''Instantiate Logistic Regression Model'''\n",
    "log_reg_model_tv2 = LogisticRegression()\n",
    "\n",
    "'''Train and Fit model'''\n",
    "log_reg_model_tv2.fit(X_train2, y_train2)\n",
    "\n",
    "'''Get predictions on test set'''\n",
    "predictions2 = log_reg_model_tv2.predict(X_test2)\n",
    "\n",
    "'''Calculate accuracy score'''\n",
    "log_accuracy2 = accuracy_score(y_test2, predictions2)\n",
    "\n",
    "'''Calculate mean coefficient'''\n",
    "coefficients_mean2 = log_reg_model_tv2.coef_.mean()\n",
    "\n",
    "print('Model Performance for Logistic Regression Count Vectoriser:')\n",
    "print('accuracy: ', log_accuracy2)\n",
    "print('Coefficient Mean: ', coefficients_mean2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc8bfd6",
   "metadata": {},
   "source": [
    "### Random Forest - TFIDVectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "eba9a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Random Forest Count Vectoriser:\n",
      "accuracy:  0.9493670886075949\n",
      "importance 2.5730091341824264e-05\n"
     ]
    }
   ],
   "source": [
    "'''Train Test Split data for modelling'''\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y_extracted2, test_size=0.2, random_state=42)\n",
    "\n",
    "'''Instantiate Random Forest Model'''\n",
    "rf_model_tv2 = RandomForestClassifier()\n",
    "\n",
    "'''Train and Fit model'''\n",
    "rf_model_tv2.fit(X_train2, y_train2)\n",
    "\n",
    "'''Get predictions on test set'''\n",
    "predictions2 = rf_model_tv2.predict(X_test2)\n",
    "\n",
    "'''Get feature importance'''\n",
    "importances_mean2 = rf_model_tv2.feature_importances_.mean()\n",
    "\n",
    "'''Calculate accuracy score'''\n",
    "rf_accuracy2 = accuracy_score(y_test2, predictions2)\n",
    "print('Model Performance for Random Forest Count Vectoriser:')\n",
    "print('accuracy: ', rf_accuracy2)\n",
    "print('importance', importances_mean2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94576992",
   "metadata": {},
   "source": [
    "\n",
    "|               | Log Regression(CV)| Log Regression(TV)|Random Forest(CV) |Random Forest(TV)|\n",
    "|---------------|-------------------|-------------------|------------------|-----------------|\n",
    "|**accuracy**   |0.954              | 0.954             | 0.941            |0.949            |\n",
    "|**coef**       |0.0002127          | 0.0022196         | -                |-                |\n",
    "|**importance** |-                  | -                 |2.57300916e-05    |2.573009e-05     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d16c6",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6ec54",
   "metadata": {},
   "source": [
    "Observed that between CountVectoriser and TfidVectoriser, the model using the TfidVectoriser performs better for RandomForest but for Logistic Regression, the accuracy remains the same at 0.954"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a1575",
   "metadata": {},
   "source": [
    "## Overall Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d1f3d",
   "metadata": {},
   "source": [
    "The table below shows the best performing model using only the tokenized join comments(M1) and using both the tokenised joined comments and author (M2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327859f",
   "metadata": {},
   "source": [
    "|               | Log Regression(TV) - M1 | Log Regression(TV) - M2|\n",
    "|---------------|-------------------------|------------------------|\n",
    "|**accuracy**   |0.982                    | 0.954                  | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615c6639",
   "metadata": {},
   "source": [
    "It is observed that best perfoming model comes from Log Regression(TV) - M1 which has a higher accuracy of 0.982. It appears that adding author column reduced the accuracy. This implies that the author column may have have increased variability potentially in the following ways where there are different authors posting to machine learning subreddit and statistics subreddit respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ab489",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635bf377",
   "metadata": {},
   "source": [
    "The initial exploratory analysis using CountVectoriser revealed interesting insights on both the machine learning subreddit and statistics subreddit. The insights identified are as followed:\n",
    "- 'data' and 'model'are words which are commently used both subreddit. 'data' has a higher count in statistics subreddit and 'model' has the higher count in machine learning subreddit.\n",
    "- 'http' is a common term that is found within both subreddit but it is observed that that machine learning has more posts containing http indicating references to URLs.\n",
    "\n",
    "It is observed that the discussion in the statistics revolved around statistics concepts and methods with references to statistical terms such as statistical terms such as 'mean','variable', 'statistics, 'hypothesis', 'linear'.\n",
    "\n",
    "It is observed that coding is more closely related to the community such as 'github' and 'code'. Words such as 'chatgpt', 'gpt','openai', 'ai' indicates that artificial intelligence is a topic of interest within the community itself.\n",
    "\n",
    "The machine learning community is also more active with more posts per month.\n",
    "\n",
    "Results from Log Regression(TV) - M1 with an accuracy of 0.982 which only analyses the joined tokenised comments indicates that just from the discussion itself (e.g. title, sub_text, comments) contains sufficient unique features to distinguish post from one another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7c6897",
   "metadata": {},
   "source": [
    "## Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd75f4",
   "metadata": {},
   "source": [
    "The currently insights is useful from the perspective of the primary stakeholders who could be people interested to move into the machine learning field as data scientist.\n",
    "- Insights from the post would be coding seems to be a relevant skill set.\n",
    "- Other insights would be Machine Learning and Statistics are similar in certain discussions but the topic discussed can still be accurately predicted for their respective thread. This implies that despite the perceived similarities, there are differences between the posts on the topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de8a94b",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3d41a",
   "metadata": {},
   "source": [
    "1) Overcoming the limitations in the number of post retrieved to more than 1000 post with future libraries improvement:\n",
    "- Limitations from 1000~ post could affect the accuracy of analysis such as the trend of author activity within the same time period. Given that the machine learning subreddit is more active, 1000 post may contain only 2 months posts compared to statistiics which may have 3 months of post.\n",
    "\n",
    "2) Further explore the models with different models such as KMeans to identify the relationships between the clusters.\n",
    "\n",
    "3) Exploring the dataset in different ways such as:\n",
    "- segregating the comments and replies into different levels for analysis.\n",
    "- exploring the content of the reference link that are sent to find common topics of interest\n",
    "- exploring the community if there are active in both threads or only statistics or machine learning subreddit respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
